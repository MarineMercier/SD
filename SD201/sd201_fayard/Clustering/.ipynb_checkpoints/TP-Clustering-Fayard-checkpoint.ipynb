{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens the csv and converts the figures that are strings into float\n",
    "\n",
    "def open_file(workfile):\n",
    "    L=[]\n",
    "    f=open(workfile, \"r\")\n",
    "    for line in f:\n",
    "        l= [x for x in line.split(\",\")]\n",
    "        L.append(l)\n",
    "    lenght=len(L[0])\n",
    "    for i in range(1, len(L)):\n",
    "        for j in range(1,lenght):\n",
    "            L[i][j]=float(L[i][j])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workfile=\"./data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array ready to be used in the kmeans algorithm\n",
    "\n",
    "def required_list_for_clustering(L):\n",
    "    l=[] \n",
    "    for i in range(1,len(L)):\n",
    "        l2=[j for j in L[i]]\n",
    "        del l2[0]                \n",
    "        l.append(l2)\n",
    "    return np.asarray(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(L,k,ini='random',max_=1000,n_in=100):\n",
    "    kmeans=KMeans(init=ini,n_clusters=k,max_iter=max_,n_init=n_in).fit(L)\n",
    "    return kmeans.predict(L), kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Our material for k-means :\n",
    "\n",
    "L=required_list_for_clustering(open_file(workfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function SSE, which calculates the square of the distances to the centroids of the cluster for each \n",
    "#point and do the sum\n",
    "\n",
    "def SSE(L,k,ini='random',max_=1000,n_in=100):\n",
    "    predict, center=kmeans(L,k,ini,max_,n_in)\n",
    "    s=0\n",
    "    for i in range(k):\n",
    "        for j in range(len(predict)):\n",
    "            if predict[j]==i:\n",
    "                for m in range(len(L[j])):\n",
    "                    s+=(L[j][m]-center[i][m])**2\n",
    "    return s\n",
    "                    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1590.816835111399"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First test :\n",
    "\n",
    "SSE(L,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 : Playing with the parameters to decrease SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, I think that we can decrase the SSE by choosing better our initial centers, ie by usink k-means ++ instead of k-mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not necessary that it's going to improve the SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1544.5883338858732"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSE(L,8,'k-means++')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My prevision was true : the SSE is inferior to the former result, because our initialization was better. (1529<1578)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the other hand, we can also play with the number of iteration. \n",
    "For now, the maximum number of iteration is 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think that by doing more iteration, our result will become more accurate. But in fact, it's not always the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600.5496443758714"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSE(L,8,'random',max_=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1613.0267347735933"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSE(L,8,'random',max_=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1621.019341052785"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSE(L,8,'random',max_=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result are very different at the end of each test, which proves that it do not have a huge impact on SSE. \n",
    "We keep 10000 which is on the average the better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, we can play with the number n_init. If we test more possibilities for initila centroids, we can wonder that the algorithm will run more efficiently, but it is not necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare the efficiency of n_in by increasing it steadily : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 1509.4291397575112)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_init=5\n",
    "best_n_init=5\n",
    "res=SSE(L,8,'k-means++',max_=10000,n_in=n_init)\n",
    "for i in range(10):\n",
    "    n_init=n_init*2\n",
    "    a=SSE(L,8,'k-means++',max_=10000,n_in=n_init)\n",
    "    if a<res:\n",
    "        res=a\n",
    "        best_n_init=n_init\n",
    "        \n",
    "best_n_init, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not obtain the same value for each test.\n",
    "That proves that it don't decrease necessarily the SSE. \n",
    "But in general, we can notice that it is preferable to have a huge value for the number of initialisations tested in order to have a low SSE, what is logical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESULT : With the parameters \"k-means++\", a number max of iterations equals to 10000, and a n-in equals to 5120, I obtained an SSE of 1508, better than the 1560 obtained at the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep the parameters obtained at question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(workfile,k=8,n_init=5120,max_iter=10000,ini='k-means++'):\n",
    "    res=[]\n",
    "    L=required_list_for_clustering(workfile)\n",
    "    predict,cluster_center=kmeans(L,k,ini,max_iter,n_init)\n",
    "    for i in range(k):\n",
    "        L=[]\n",
    "        for j in range(len(predict)):\n",
    "            if predict[j]==i:\n",
    "                L.append(workfile[j+1][0])\n",
    "        res.append(L)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['American Express', 'Boeing', 'Microsoft', 'Walt Disney', 'JPMorgan Chase'],\n",
       " ['IBM',\n",
       "  'The Home Depot',\n",
       "  'Intel',\n",
       "  'Wal-Mart',\n",
       "  'General Electric',\n",
       "  'United Technologies',\n",
       "  'Travelers',\n",
       "  '3M'],\n",
       " ['Chevron', 'Pfizer', 'ExxonMobil'],\n",
       " ['Kraft',\n",
       "  'Verizon',\n",
       "  'Procter & Gamble',\n",
       "  'AT&T',\n",
       "  'Merck',\n",
       "  'McDonalds',\n",
       "  'Coca-Cola',\n",
       "  'Johnson & Johnson'],\n",
       " ['Hewlett-Packard'],\n",
       " ['DuPont', 'Caterpillar', 'Alcoa'],\n",
       " ['Cisco Systems'],\n",
       " ['Bank of America']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workfile=\"./data.csv\"\n",
    "workfile=open_file(workfile)\n",
    "cluster=cluster(workfile)\n",
    "cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First cluster :  JUNK FOOD & TELECOM\n",
    "\n",
    "['Kraft','Verizon','Procter & Gamble','AT&T','Merck','McDonalds','Coca-Cola','Johnson & Johnson']\n",
    "\n",
    "McDO and Coca are often in the same cluster.\n",
    "We have also telecoms, with AT&T and Verizon.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second cluster : INFORMATIC\n",
    "    \n",
    "['IBM','The Home Depot','Intel','Wal-Mart','General Electric','United Technologies','Travelers','3M']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third cluster : BANK \n",
    "    \n",
    "['American Express', 'Boeing', 'Microsoft', 'Walt Disney', 'JPMorgan Chase']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth : HP, unfortunately it is not in the second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fifth : Cisco, idem..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sixth : ENERGY \n",
    "    \n",
    "['Chevron', 'Pfizer', 'ExxonMobil']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seventh: Bank of America, unfortunately it is not in the third"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eighth : Divers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
