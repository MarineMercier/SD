{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# Test of lambda fonctions \n",
    "\n",
    "A=list(map(lambda a : a+1 , [1,2,3,4]))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unbound method textFile() must be called with SparkContext instance as first argument (got str instance instead)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2d5be249fa95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Datasets/steve.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(lines.take(5))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unbound method textFile() must be called with SparkContext instance as first argument (got str instance instead)"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext as sc\n",
    "\n",
    "lines=sc.textFile(\"./Datasets/steve.txt\")       \n",
    "#print(lines.take(5))\n",
    "words=lines.flatMap(lambda line : line.split(\" \"))\n",
    "for a in words.take(5):\n",
    "  print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"> : 10\n",
       "&quot;Catholic, : 1\n",
       "&quot;I : 1\n",
       "&quot;John&quot; : 1\n",
       "&quot;Think : 1\n",
       "&quot;adoptive : 1\n",
       "&quot;aggressive, : 1\n",
       "&quot;alcoholic : 1\n",
       "&quot;doctor : 1\n",
       "&quot;he : 1\n",
       "&quot;it : 1\n",
       "&quot;my : 1\n",
       "&quot;one : 1\n",
       "&quot;repo : 1\n",
       "&quot;threatened : 1\n",
       "&quot;was : 2\n",
       "&quot;were : 1\n",
       "&quot;without : 1\n",
       "(/dʒɒbz/; : 1\n",
       "(1922–1993), : 1\n",
       "(1924–1986). : 1\n",
       "(Arabic: : 1\n",
       "(CEO), : 1\n",
       "(GUI). : 1\n",
       "(b. : 2\n",
       "... : 3\n",
       "1, : 1\n",
       "1,000%.&quot;[12] : 1\n",
       "15, : 1\n",
       "17-year-old : 1\n",
       "1930s : 1\n",
       "1931), : 1\n",
       "1932), : 1\n",
       "1946.[12] : 1\n",
       "1952.[12] : 1\n",
       "1954 : 1\n",
       "1954.[15] : 1\n",
       "1955 : 1\n",
       "1955, : 1\n",
       "1955.[12] : 1\n",
       "1960s.[4] : 1\n",
       "1970s : 1\n",
       "1972 : 1\n",
       "1974 : 1\n",
       "1976 : 1\n",
       "1979, : 1\n",
       "1980s. : 1\n",
       "1983, : 1\n",
       "1984. : 1\n",
       "1985 : 1\n",
       "1985.[9] : 1\n",
       "1986.[10] : 1\n",
       "1997 : 1\n",
       "1997, : 1\n",
       "2001, : 1\n",
       "2003 : 1\n",
       "2011) : 1\n",
       "2011, : 1\n",
       "23 : 1\n",
       "24, : 2\n",
       "5, : 2\n",
       "Abdulfattah : 2\n",
       "According : 1\n",
       "After : 3\n",
       "Although : 1\n",
       "Alto, : 1\n",
       "American : 2\n",
       "And : 2\n",
       "App : 1\n",
       "Apple : 11\n",
       "Apple, : 1\n",
       "Arab : 1\n",
       "Arabs : 1\n",
       "Area : 2\n",
       "Armenian : 1\n",
       "As : 2\n",
       "August : 1\n",
       "Background : 1\n",
       "Bay : 2\n",
       "Beginning : 1\n",
       "Beirut, : 1\n",
       "Brennan, : 1\n",
       "Buddhism.[6] : 1\n",
       "But : 1\n",
       "CEO : 3\n",
       "Calvinist : 1\n",
       "Carole : 1\n",
       "Catholic : 1\n",
       "Chrisann : 2\n",
       "Clara : 8\n",
       "Clara, : 1\n",
       "Clara.[19] : 1\n",
       "Coast : 2\n",
       "College : 1\n",
       "Company&apos;s : 1\n",
       "Dean; : 1\n",
       "Disney : 1\n",
       "District : 1\n",
       "Even : 1\n",
       "FBI : 1\n",
       "Family : 1\n",
       "February : 2\n",
       "Following : 1\n",
       "Francisco : 6\n",
       "Francisco&apos;s : 1\n",
       "Francisco.[15] : 1\n",
       "GUI, : 1\n",
       "George : 1\n",
       "German : 1\n",
       "Germantown, : 1\n",
       "Guard : 2\n",
       "Hagopian : 1\n",
       "Hagopian. : 1\n",
       "He : 5\n",
       "His : 2\n",
       "Homs, : 2\n",
       "I : 6\n",
       "II, : 2\n",
       "In : 6\n",
       "Inc.; : 1\n",
       "India : 1\n",
       "Isaacson, : 1\n",
       "Ive : 1\n",
       "James : 1\n",
       "Jandali : 8\n",
       "Jandali, : 1\n",
       "Jandali: : 1\n",
       "Joanne : 5\n",
       "Jobs : 23\n",
       "Jobs&apos;s : 8\n",
       "Jobs, : 1\n",
       "Jonathan : 1\n",
       "LSD : 2\n",
       "LaserWriter, : 1\n",
       "Laurene : 1\n",
       "Lebanon, : 1\n",
       "Lisa : 1\n",
       "Lucas&apos;s : 1\n",
       "Lucasfilm : 1\n",
       "Mac : 2\n",
       "Macintosh : 2\n",
       "Many : 1\n",
       "March : 1\n",
       "Meanwhile, : 1\n",
       "Michigan : 1\n",
       "Middle-Eastern : 1\n",
       "Midwest : 1\n",
       "Mona : 1\n",
       "Mr. : 1\n",
       "Mrs. : 1\n",
       "Muslim : 1\n",
       "Muslim. : 1\n",
       "NeXT&apos;s : 1\n",
       "NeXT, : 1\n",
       "NeXT. : 2\n",
       "NeXTSTEP : 1\n",
       "OS : 3\n",
       "October : 2\n",
       "PARC, : 1\n",
       "Paul : 11\n",
       "PhD : 1\n",
       "Pixar, : 1\n",
       "Pixar; : 1\n",
       "Pixar;[3] : 1\n",
       "Reed : 1\n",
       "Reinhold : 1\n",
       "San : 8\n",
       "Schieble : 8\n",
       "Schieble&apos;s : 2\n",
       "Schieble. : 1\n",
       "She : 1\n",
       "Simpson, : 1\n",
       "So : 1\n",
       "States : 2\n",
       "Steve : 6\n",
       "Steve, : 1\n",
       "Steven : 1\n",
       "Store, : 3\n",
       "Story—an : 1\n",
       "Sunset : 1\n",
       "Swiss : 1\n",
       "Syria : 1\n",
       "Syria. : 2\n",
       "That&apos;s : 1\n",
       "The : 6\n",
       "They : 1\n",
       "This : 1\n",
       "Toy : 1\n",
       "United : 2\n",
       "University : 2\n",
       "Unix-based : 1\n",
       "Walt : 1\n",
       "Walter : 1\n",
       "War : 1\n",
       "When : 2\n",
       "While : 1\n",
       "Wisconsin, : 1\n",
       "Wisconsin. : 1\n",
       "Wisconsin.[12][11][13] : 1\n",
       "Wisconsin.[12][15] : 1\n",
       "With : 1\n",
       "Within : 1\n",
       "World : 1\n",
       "Wozniak : 2\n",
       "Wozniak&apos;s : 1\n",
       "X, : 1\n",
       "Xerox : 1\n",
       "Zen : 1\n",
       "[Steve] : 1\n",
       "a : 45\n",
       "abortions : 1\n",
       "abusive&quot; : 1\n",
       "acquaintance : 1\n",
       "acquisition : 1\n",
       "activist : 1\n",
       "activities.[11] : 1\n",
       "addition : 2\n",
       "addition, : 2\n",
       "additionally : 1\n",
       "admitted : 1\n",
       "adopt : 1\n",
       "adoption : 4\n",
       "adoption.&quot;[17] : 1\n",
       "adoptions.&quot;[12] : 1\n",
       "adoptive : 3\n",
       "advertising : 1\n",
       "after : 4\n",
       "against : 1\n",
       "age.[14] : 1\n",
       "aggravate : 1\n",
       "already : 1\n",
       "also : 2\n",
       "although : 1\n",
       "am : 1\n",
       "an : 10\n",
       "and : 53\n",
       "anyone : 1\n",
       "are : 2\n",
       "are, : 1\n",
       "around : 1\n",
       "arranged : 1\n",
       "arrest : 1\n",
       "as : 13\n",
       "assistant : 1\n",
       "at : 6\n",
       "attempt : 1\n",
       "attempts : 1\n",
       "attend : 1\n",
       "attended : 1\n",
       "aware : 1\n",
       "away : 1\n",
       "babies, : 1\n",
       "baby : 5\n",
       "bank : 1\n",
       "bank. : 1\n",
       "bankruptcy. : 1\n",
       "based : 1\n",
       "bearing : 1\n",
       "became : 2\n",
       "because : 1\n",
       "become : 1\n",
       "been : 3\n",
       "before : 1\n",
       "before, : 1\n",
       "being : 1\n",
       "best : 1\n",
       "bet : 1\n",
       "biographer : 1\n",
       "biographer, : 1\n",
       "biological : 5\n",
       "birth : 1\n",
       "birth; : 1\n",
       "blessed : 1\n",
       "blind : 1\n",
       "blue : 1\n",
       "board : 1\n",
       "bore : 1\n",
       "born : 2\n",
       "both : 2\n",
       "boy : 1\n",
       "breakthrough : 1\n",
       "bring : 1\n",
       "business : 2\n",
       "but : 3\n",
       "by : 4\n",
       "campaign, : 1\n",
       "candidate, : 1\n",
       "care : 1\n",
       "career : 1\n",
       "cars, : 1\n",
       "case, : 1\n",
       "chairman, : 2\n",
       "changed : 1\n",
       "chief : 1\n",
       "child : 2\n",
       "chose : 1\n",
       "closed : 1\n",
       "closely : 1\n",
       "co-founded : 1\n",
       "co-founder : 2\n",
       "collar : 1\n",
       "college : 2\n",
       "college.[12] : 1\n",
       "college.[7] : 1\n",
       "comment : 1\n",
       "commercial : 1\n",
       "company : 1\n",
       "company, : 1\n",
       "company; : 1\n",
       "completely : 1\n",
       "completely&quot; : 1\n",
       "computer : 3\n",
       "computer-animated : 1\n",
       "computer. : 1\n",
       "computers : 1\n",
       "computers. : 1\n",
       "consented : 1\n",
       "consider : 1\n",
       "continued : 1\n",
       "couple : 3\n",
       "course : 1\n",
       "court : 1\n",
       "cultural : 1\n",
       "cut : 1\n",
       "dad. : 1\n",
       "dangerous, : 1\n",
       "date : 1\n",
       "dating : 1\n",
       "daughter : 2\n",
       "days : 1\n",
       "decided : 3\n",
       "declassified : 1\n",
       "deeply : 1\n",
       "deliberately : 1\n",
       "delivered : 1\n",
       "descent, : 1\n",
       "designer : 1\n",
       "designer. : 1\n",
       "desktop : 1\n",
       "develop : 1\n",
       "development : 3\n",
       "diagnosed : 1\n",
       "did : 5\n",
       "died : 1\n",
       "different : 1\n",
       "different&quot; : 1\n",
       "difficult : 1\n",
       "directors : 1\n",
       "division : 1\n",
       "docked : 1\n",
       "doctoral : 1\n",
       "don&apos;t : 1\n",
       "dropped : 1\n",
       "dropping : 1\n",
       "during : 2\n",
       "dying : 1\n",
       "economics : 1\n",
       "ectopic : 1\n",
       "education, : 1\n",
       "effects : 1\n",
       "egg : 1\n",
       "engaged : 1\n",
       "engine-room : 1\n",
       "enlightenment : 1\n",
       "entrepreneur, : 1\n",
       "event : 1\n",
       "eventually : 3\n",
       "everyone.&quot;[17] : 1\n",
       "executive : 1\n",
       "fame : 1\n",
       "family : 4\n",
       "family[18] : 1\n",
       "farm : 2\n",
       "father : 3\n",
       "father, : 2\n",
       "father.[12] : 1\n",
       "feature : 1\n",
       "felt : 3\n",
       "few : 2\n",
       "film, : 1\n",
       "financial : 1\n",
       "find : 1\n",
       "first : 6\n",
       "followed : 1\n",
       "following : 1\n",
       "for : 12\n",
       "forbade : 1\n",
       "forced : 1\n",
       "former : 1\n",
       "found : 1\n",
       "foundation : 1\n",
       "founder, : 1\n",
       "frightened : 1\n",
       "from : 2\n",
       "full : 1\n",
       "fully : 1\n",
       "funded : 1\n",
       "gained : 1\n",
       "gave : 1\n",
       "girl : 1\n",
       "girlfriend, : 1\n",
       "give : 1\n",
       "giving : 1\n",
       "go : 1\n",
       "going : 1\n",
       "grandparents : 1\n",
       "graphical : 1\n",
       "graphics : 1\n",
       "graphics. : 1\n",
       "grew : 4\n",
       "had : 11\n",
       "halted : 1\n",
       "happy : 1\n",
       "harsh, : 1\n",
       "has : 2\n",
       "have : 3\n",
       "having : 1\n",
       "he : 19\n",
       "helped : 1\n",
       "her : 5\n",
       "herself : 1\n",
       "high : 2\n",
       "higher-education : 1\n",
       "highly : 1\n",
       "him : 6\n",
       "him, : 1\n",
       "him. : 1\n",
       "him.&quot;[18] : 1\n",
       "his : 15\n",
       "hobby, : 1\n",
       "household,[15] : 1\n",
       "household.[11] : 1\n",
       "housewife.[11] : 1\n",
       "however, : 1\n",
       "husband : 1\n",
       "iMac, : 1\n",
       "iPad. : 1\n",
       "iPhone, : 1\n",
       "iPod, : 1\n",
       "iTunes : 2\n",
       "if : 1\n",
       "illegal : 1\n",
       "immigrants, : 1\n",
       "important : 1\n",
       "in : 41\n",
       "including : 1\n",
       "indulged : 1\n",
       "industrial : 1\n",
       "industry : 2\n",
       "initially : 1\n",
       "initiate : 1\n",
       "instead.[18] : 1\n",
       "interface : 1\n",
       "into : 1\n",
       "introduced : 1\n",
       "inventor, : 1\n",
       "involve : 1\n",
       "is : 1\n",
       "it : 2\n",
       "it&apos;s : 2\n",
       "its : 2\n",
       "jail : 1\n",
       "joined : 1\n",
       "just : 1\n",
       "killed : 1\n",
       "knew : 1\n",
       "knowing, : 1\n",
       "larger : 1\n",
       "laser : 1\n",
       "later : 3\n",
       "later, : 1\n",
       "latter : 1\n",
       "law, : 1\n",
       "leading : 1\n",
       "leave : 1\n",
       "leaving : 1\n",
       "led : 1\n",
       "left : 1\n",
       "life : 1\n",
       "life.[8] : 1\n",
       "line : 1\n",
       "lived : 1\n",
       "long : 1\n",
       "looking : 1\n",
       "lot : 1\n",
       "love : 2\n",
       "loved : 1\n",
       "machinist.[15] : 1\n",
       "made : 3\n",
       "magnate, : 1\n",
       "majority : 1\n",
       "man&quot;, : 1\n",
       "marijuana : 1\n",
       "markets. : 1\n",
       "married : 2\n",
       "marry : 1\n",
       "marry.[12] : 1\n",
       "mass-produced : 2\n",
       "maternal : 1\n",
       "matter : 1\n",
       "me : 2\n",
       "me, : 2\n",
       "me. : 1\n",
       "member : 1\n",
       "members : 1\n",
       "merged : 1\n",
       "merger, : 1\n",
       "met : 1\n",
       "microcomputer : 1\n",
       "millionaire : 1\n",
       "mind, : 1\n",
       "mistake. : 1\n",
       "modern : 1\n",
       "months : 2\n",
       "more.&quot;[12] : 1\n",
       "most : 1\n",
       "mother : 3\n",
       "mother&apos;s : 1\n",
       "mother, : 1\n",
       "mothers, : 1\n",
       "mouse-driven : 1\n",
       "move : 1\n",
       "moves, : 1\n",
       "much : 2\n",
       "my : 1\n",
       "neither : 1\n",
       "neuroendocrine : 1\n",
       "new : 2\n",
       "not : 8\n",
       "noted : 1\n",
       "notes : 1\n",
       "nothing : 1\n",
       "of : 41\n",
       "off : 1\n",
       "officer : 1\n",
       "official : 2\n",
       "on : 6\n",
       "once : 1\n",
       "one : 1\n",
       "only : 2\n",
       "onto : 1\n",
       "option : 1\n",
       "or : 1\n",
       "original : 1\n",
       "ostensible : 1\n",
       "out : 3\n",
       "out,[5] : 1\n",
       "pancreatic : 1\n",
       "papers.[12] : 1\n",
       "parents : 4\n",
       "parents&quot; : 1\n",
       "parents, : 1\n",
       "parents.&quot;[19] : 1\n",
       "part : 1\n",
       "personal : 2\n",
       "personality.&quot;[15] : 1\n",
       "pioneers : 1\n",
       "place.&quot;[17] : 1\n",
       "placed : 2\n",
       "platform : 1\n",
       "platform, : 1\n",
       "political : 2\n",
       "possible : 1\n",
       "potential : 1\n",
       "power : 1\n",
       "pregnancy, : 1\n",
       "pregnant : 1\n",
       "printer : 1\n",
       "process: : 1\n",
       "produce : 1\n",
       "products : 1\n",
       "promised : 1\n",
       "promptly : 1\n",
       "publishing : 1\n",
       "pursued : 1\n",
       "put : 2\n",
       "quietly : 1\n",
       "raised : 2\n",
       "raising : 1\n",
       "ramifications: : 1\n",
       "really : 2\n",
       "rebuilt : 1\n",
       "recognized : 1\n",
       "referred : 2\n",
       "refused : 1\n",
       "regard : 1\n",
       "related : 1\n",
       "relationship.[12] : 1\n",
       "releasing : 1\n",
       "replaced : 1\n",
       "report : 1\n",
       "reporter : 1\n",
       "resemblance : 1\n",
       "respiratory : 1\n",
       "return : 1\n",
       "revived : 1\n",
       "revolution : 1\n",
       "rise : 1\n",
       "sadly, : 1\n",
       "same : 1\n",
       "saw : 1\n",
       "say : 1\n",
       "scared : 1\n",
       "school, : 2\n",
       "science.[11] : 1\n",
       "seeking : 1\n",
       "self-made : 1\n",
       "sell : 1\n",
       "series : 1\n",
       "settled : 1\n",
       "several : 1\n",
       "shame : 1\n",
       "shared : 1\n",
       "shareholder : 1\n",
       "she : 6\n",
       "sheltered : 1\n",
       "ship : 1\n",
       "sign : 1\n",
       "single : 1\n",
       "sister, : 1\n",
       "six : 1\n",
       "so : 3\n",
       "sometimes : 1\n",
       "son : 2\n",
       "specialized : 1\n",
       "spent : 2\n",
       "sperm : 2\n",
       "spinout : 1\n",
       "start : 1\n",
       "state-of-the-art : 1\n",
       "stated : 4\n",
       "states : 1\n",
       "stigma : 1\n",
       "strong : 1\n",
       "struggle, : 1\n",
       "student : 1\n",
       "study : 2\n",
       "studying : 1\n",
       "subject : 1\n",
       "successful : 1\n",
       "sudden : 1\n",
       "suited : 1\n",
       "summer : 1\n",
       "support. : 1\n",
       "take : 2\n",
       "taking : 1\n",
       "taking, : 1\n",
       "tattoos, : 1\n",
       "teaching : 1\n",
       "telling : 1\n",
       "ten : 1\n",
       "that : 22\n",
       "that[18] : 1\n",
       "the : 66\n",
       "their : 5\n",
       "them : 3\n",
       "then : 3\n",
       "there : 2\n",
       "they : 5\n",
       "thing, : 1\n",
       "things&quot; : 1\n",
       "this : 1\n",
       "thought : 1\n",
       "three : 1\n",
       "through : 1\n",
       "time : 2\n",
       "time, : 1\n",
       "time. : 1\n",
       "to : 42\n",
       "told : 3\n",
       "too : 2\n",
       "took : 2\n",
       "tough : 1\n",
       "tour : 1\n",
       "traditional : 1\n",
       "traveled : 2\n",
       "tumor : 1\n",
       "tumor. : 1\n",
       "two : 3\n",
       "tyrant, : 1\n",
       "undergraduate : 1\n",
       "unsuccessful : 1\n",
       "unusual.&quot;[14] : 1\n",
       "unwed : 1\n",
       "up : 6\n",
       "upped : 1\n",
       "upset : 1\n",
       "used : 1\n",
       "user : 1\n",
       "vector : 1\n",
       "verge : 1\n",
       "very : 1\n",
       "visionaries : 1\n",
       "visual : 1\n",
       "want : 3\n",
       "wanted : 3\n",
       "war. : 1\n",
       "was : 33\n",
       "was, : 1\n",
       "wasn&apos;t : 1\n",
       "way : 1\n",
       "we : 2\n",
       "wealth : 1\n",
       "wealthy.&quot;[18] : 1\n",
       "wedlock : 1\n",
       "well-educated, : 1\n",
       "went : 1\n",
       "were : 10\n",
       "when : 4\n",
       "where : 1\n",
       "which : 2\n",
       "while : 1\n",
       "who : 5\n",
       "whom : 1\n",
       "widely : 1\n",
       "wife : 2\n",
       "with : 15\n",
       "without : 1\n",
       "women : 1\n",
       "won : 1\n",
       "work.[12][15] : 1\n",
       "worked : 1\n",
       "would : 6\n",
       "year : 1\n",
       "years : 2\n",
       "young : 1\n",
       "الجندلي) : 1\n",
       "الفتاح : 1\n",
       "عبد : 1\n",
       "– : 1\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "lines=sc.textFile(\"/FileStore/tables/steve.txt\")   #we open the file steve.txt\n",
    "words=lines.flatMap(lambda line : line.split(\" \"))  #we split at every word \n",
    "cpteur=words.map( lambda s : 1 )                    # we use map reduce functions in order to count the number of words in the text\n",
    "pairs=words.map( lambda s : (s,1))\n",
    "number_of_words=cpteur.reduce(lambda a , b : a+b)\n",
    "counts = pairs.reduceByKey( lambda a , b : a + b )\n",
    "counts=counts.sortByKey()                           # we sort the data using the alphabetic order \n",
    "for (count,word) in counts.take(number_of_words):    # we print every word associated with his number of occurences in the text \n",
    "  print(\"%s : %i\" % (count,word))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">the : 66\n",
       "and : 53\n",
       "a : 45\n",
       "to : 42\n",
       "in : 41\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_counts=counts.sortBy( lambda x : x[1] , False)  #we use the question 1 and we just modifiy the order of the data by sorting them using their second arguments x[1]\n",
    "for (count,word) in new_counts.take(5):             #we print only the five first word of our data \n",
    "  print(\"%s : %i\" % (count,word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Apple : 11\n",
       "Clara : 8\n",
       "Jandali : 8\n",
       "Jobs&apos;s : 8\n",
       "Schieble : 8\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_counts2=counts.filter( lambda x : len(x[0])>4 )       #we use again the data in \"counts\" but we filter and we keep only those who have more than five letter\n",
    "new_counts2=new_counts2.sortBy( lambda x : x[1] , False)  #then we sort them as in Question 2 \n",
    "for (count,word) in new_counts2.take(5):\n",
    "  print(\"%s : %i\" % (count,word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">(&apos;60589&apos;, (&apos;United States&apos;, 8145))\n",
       "(&apos;30594&apos;, (&apos;France&apos;, 7799))\n",
       "(&apos;24449&apos;, (&apos;Communes of France&apos;, 5740))\n",
       "(&apos;26539&apos;, (&apos;Departments of France&apos;, 5299))\n",
       "(&apos;51359&apos;, (&apos;Regions of France&apos;, 4064))\n",
       "(&apos;23683&apos;, (&apos;City&apos;, 3832))\n",
       "(&apos;52174&apos;, (&apos;Romania&apos;, 3527))\n",
       "(&apos;20409&apos;, (&apos;Category:Rivers in Romania&apos;, 2978))\n",
       "(&apos;59931&apos;, (&apos;Tributary&apos;, 2799))\n",
       "(&apos;28563&apos;, (&apos;England&apos;, 2277))\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edgelist = sc.textFile(\"/FileStore/tables/edgelist.txt\")\n",
    "idslabels = sc.textFile(\"/FileStore/tables/idslabels.txt\")\n",
    "\n",
    "lines_edgelist =edgelist.flatMap(lambda line: line.split(\" \")[1:])    #we don't keep the first element of the line, because it doesn't count in the in-degree       \n",
    "pairs = lines_edgelist.map( lambda s :(s,1))\n",
    "counts = pairs.reduceByKey(lambda a,b : a+b)                          #we count the in-degree of every pages\n",
    "\n",
    "lines_idslabels = idslabels.flatMap(lambda line : line.split(\"\\n\"))   \n",
    "couples = lines_idslabels.map (lambda s : (s.split(\" \")[0],(\" \").join(s.split(\" \")[1:])))  #the first element of the couple is the id of the page, and the second is the name of the page\n",
    "jointure = couples.join(counts)                                                            #we join with the id, so we have (the id, (the name of the website, his in-dregree))\n",
    "jointure_sorted = jointure.sortBy(lambda a : a[1][-1], False).collect()                    #we sort the in-dregrees\n",
    "resultat = jointure_sorted[:10]\n",
    "for i in resultat : \n",
    "  print(i)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  },
  "name": "TP 2 Spark",
  "notebookId": 1215196057622588
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
