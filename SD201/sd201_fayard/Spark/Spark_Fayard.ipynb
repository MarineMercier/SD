{"cells":[{"cell_type":"code","source":["# Test of lambda fonctions \n\nA=list(map(lambda a : a+1 , [1,2,3,4]))\nprint(A)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[2, 3, 4, 5]\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["lines=sc.textFile(\"/FileStore/tables/steve.txt\")       \n#print(lines.take(5))\nwords=lines.flatMap(lambda line : line.split(\" \"))\nfor a in words.take(5):\n  print(a)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Steven\nPaul\nJobs\n(/dʒɒbz/;\nFebruary\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["  \n\nlines=sc.textFile(\"/FileStore/tables/steve.txt\")   #we open the file steve.txt\nwords=lines.flatMap(lambda line : line.split(\" \"))  #we split at every word \ncpteur=words.map( lambda s : 1 )                    # we use map reduce functions in order to count the number of words in the text\npairs=words.map( lambda s : (s,1))\nnumber_of_words=cpteur.reduce(lambda a , b : a+b)\ncounts = pairs.reduceByKey( lambda a , b : a + b )\ncounts=counts.sortByKey()                           # we sort the data using the alphabetic order \nfor (count,word) in counts.take(number_of_words):    # we print every word associated with his number of occurences in the text \n  print(\"%s : %i\" % (count,word))\n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"> : 10\n&quot;Catholic, : 1\n&quot;I : 1\n&quot;John&quot; : 1\n&quot;Think : 1\n&quot;adoptive : 1\n&quot;aggressive, : 1\n&quot;alcoholic : 1\n&quot;doctor : 1\n&quot;he : 1\n&quot;it : 1\n&quot;my : 1\n&quot;one : 1\n&quot;repo : 1\n&quot;threatened : 1\n&quot;was : 2\n&quot;were : 1\n&quot;without : 1\n(/dʒɒbz/; : 1\n(1922–1993), : 1\n(1924–1986). : 1\n(Arabic: : 1\n(CEO), : 1\n(GUI). : 1\n(b. : 2\n... : 3\n1, : 1\n1,000%.&quot;[12] : 1\n15, : 1\n17-year-old : 1\n1930s : 1\n1931), : 1\n1932), : 1\n1946.[12] : 1\n1952.[12] : 1\n1954 : 1\n1954.[15] : 1\n1955 : 1\n1955, : 1\n1955.[12] : 1\n1960s.[4] : 1\n1970s : 1\n1972 : 1\n1974 : 1\n1976 : 1\n1979, : 1\n1980s. : 1\n1983, : 1\n1984. : 1\n1985 : 1\n1985.[9] : 1\n1986.[10] : 1\n1997 : 1\n1997, : 1\n2001, : 1\n2003 : 1\n2011) : 1\n2011, : 1\n23 : 1\n24, : 2\n5, : 2\nAbdulfattah : 2\nAccording : 1\nAfter : 3\nAlthough : 1\nAlto, : 1\nAmerican : 2\nAnd : 2\nApp : 1\nApple : 11\nApple, : 1\nArab : 1\nArabs : 1\nArea : 2\nArmenian : 1\nAs : 2\nAugust : 1\nBackground : 1\nBay : 2\nBeginning : 1\nBeirut, : 1\nBrennan, : 1\nBuddhism.[6] : 1\nBut : 1\nCEO : 3\nCalvinist : 1\nCarole : 1\nCatholic : 1\nChrisann : 2\nClara : 8\nClara, : 1\nClara.[19] : 1\nCoast : 2\nCollege : 1\nCompany&apos;s : 1\nDean; : 1\nDisney : 1\nDistrict : 1\nEven : 1\nFBI : 1\nFamily : 1\nFebruary : 2\nFollowing : 1\nFrancisco : 6\nFrancisco&apos;s : 1\nFrancisco.[15] : 1\nGUI, : 1\nGeorge : 1\nGerman : 1\nGermantown, : 1\nGuard : 2\nHagopian : 1\nHagopian. : 1\nHe : 5\nHis : 2\nHoms, : 2\nI : 6\nII, : 2\nIn : 6\nInc.; : 1\nIndia : 1\nIsaacson, : 1\nIve : 1\nJames : 1\nJandali : 8\nJandali, : 1\nJandali: : 1\nJoanne : 5\nJobs : 23\nJobs&apos;s : 8\nJobs, : 1\nJonathan : 1\nLSD : 2\nLaserWriter, : 1\nLaurene : 1\nLebanon, : 1\nLisa : 1\nLucas&apos;s : 1\nLucasfilm : 1\nMac : 2\nMacintosh : 2\nMany : 1\nMarch : 1\nMeanwhile, : 1\nMichigan : 1\nMiddle-Eastern : 1\nMidwest : 1\nMona : 1\nMr. : 1\nMrs. : 1\nMuslim : 1\nMuslim. : 1\nNeXT&apos;s : 1\nNeXT, : 1\nNeXT. : 2\nNeXTSTEP : 1\nOS : 3\nOctober : 2\nPARC, : 1\nPaul : 11\nPhD : 1\nPixar, : 1\nPixar; : 1\nPixar;[3] : 1\nReed : 1\nReinhold : 1\nSan : 8\nSchieble : 8\nSchieble&apos;s : 2\nSchieble. : 1\nShe : 1\nSimpson, : 1\nSo : 1\nStates : 2\nSteve : 6\nSteve, : 1\nSteven : 1\nStore, : 3\nStory—an : 1\nSunset : 1\nSwiss : 1\nSyria : 1\nSyria. : 2\nThat&apos;s : 1\nThe : 6\nThey : 1\nThis : 1\nToy : 1\nUnited : 2\nUniversity : 2\nUnix-based : 1\nWalt : 1\nWalter : 1\nWar : 1\nWhen : 2\nWhile : 1\nWisconsin, : 1\nWisconsin. : 1\nWisconsin.[12][11][13] : 1\nWisconsin.[12][15] : 1\nWith : 1\nWithin : 1\nWorld : 1\nWozniak : 2\nWozniak&apos;s : 1\nX, : 1\nXerox : 1\nZen : 1\n[Steve] : 1\na : 45\nabortions : 1\nabusive&quot; : 1\nacquaintance : 1\nacquisition : 1\nactivist : 1\nactivities.[11] : 1\naddition : 2\naddition, : 2\nadditionally : 1\nadmitted : 1\nadopt : 1\nadoption : 4\nadoption.&quot;[17] : 1\nadoptions.&quot;[12] : 1\nadoptive : 3\nadvertising : 1\nafter : 4\nagainst : 1\nage.[14] : 1\naggravate : 1\nalready : 1\nalso : 2\nalthough : 1\nam : 1\nan : 10\nand : 53\nanyone : 1\nare : 2\nare, : 1\naround : 1\narranged : 1\narrest : 1\nas : 13\nassistant : 1\nat : 6\nattempt : 1\nattempts : 1\nattend : 1\nattended : 1\naware : 1\naway : 1\nbabies, : 1\nbaby : 5\nbank : 1\nbank. : 1\nbankruptcy. : 1\nbased : 1\nbearing : 1\nbecame : 2\nbecause : 1\nbecome : 1\nbeen : 3\nbefore : 1\nbefore, : 1\nbeing : 1\nbest : 1\nbet : 1\nbiographer : 1\nbiographer, : 1\nbiological : 5\nbirth : 1\nbirth; : 1\nblessed : 1\nblind : 1\nblue : 1\nboard : 1\nbore : 1\nborn : 2\nboth : 2\nboy : 1\nbreakthrough : 1\nbring : 1\nbusiness : 2\nbut : 3\nby : 4\ncampaign, : 1\ncandidate, : 1\ncare : 1\ncareer : 1\ncars, : 1\ncase, : 1\nchairman, : 2\nchanged : 1\nchief : 1\nchild : 2\nchose : 1\nclosed : 1\nclosely : 1\nco-founded : 1\nco-founder : 2\ncollar : 1\ncollege : 2\ncollege.[12] : 1\ncollege.[7] : 1\ncomment : 1\ncommercial : 1\ncompany : 1\ncompany, : 1\ncompany; : 1\ncompletely : 1\ncompletely&quot; : 1\ncomputer : 3\ncomputer-animated : 1\ncomputer. : 1\ncomputers : 1\ncomputers. : 1\nconsented : 1\nconsider : 1\ncontinued : 1\ncouple : 3\ncourse : 1\ncourt : 1\ncultural : 1\ncut : 1\ndad. : 1\ndangerous, : 1\ndate : 1\ndating : 1\ndaughter : 2\ndays : 1\ndecided : 3\ndeclassified : 1\ndeeply : 1\ndeliberately : 1\ndelivered : 1\ndescent, : 1\ndesigner : 1\ndesigner. : 1\ndesktop : 1\ndevelop : 1\ndevelopment : 3\ndiagnosed : 1\ndid : 5\ndied : 1\ndifferent : 1\ndifferent&quot; : 1\ndifficult : 1\ndirectors : 1\ndivision : 1\ndocked : 1\ndoctoral : 1\ndon&apos;t : 1\ndropped : 1\ndropping : 1\nduring : 2\ndying : 1\neconomics : 1\nectopic : 1\neducation, : 1\neffects : 1\negg : 1\nengaged : 1\nengine-room : 1\nenlightenment : 1\nentrepreneur, : 1\nevent : 1\neventually : 3\neveryone.&quot;[17] : 1\nexecutive : 1\nfame : 1\nfamily : 4\nfamily[18] : 1\nfarm : 2\nfather : 3\nfather, : 2\nfather.[12] : 1\nfeature : 1\nfelt : 3\nfew : 2\nfilm, : 1\nfinancial : 1\nfind : 1\nfirst : 6\nfollowed : 1\nfollowing : 1\nfor : 12\nforbade : 1\nforced : 1\nformer : 1\nfound : 1\nfoundation : 1\nfounder, : 1\nfrightened : 1\nfrom : 2\nfull : 1\nfully : 1\nfunded : 1\ngained : 1\ngave : 1\ngirl : 1\ngirlfriend, : 1\ngive : 1\ngiving : 1\ngo : 1\ngoing : 1\ngrandparents : 1\ngraphical : 1\ngraphics : 1\ngraphics. : 1\ngrew : 4\nhad : 11\nhalted : 1\nhappy : 1\nharsh, : 1\nhas : 2\nhave : 3\nhaving : 1\nhe : 19\nhelped : 1\nher : 5\nherself : 1\nhigh : 2\nhigher-education : 1\nhighly : 1\nhim : 6\nhim, : 1\nhim. : 1\nhim.&quot;[18] : 1\nhis : 15\nhobby, : 1\nhousehold,[15] : 1\nhousehold.[11] : 1\nhousewife.[11] : 1\nhowever, : 1\nhusband : 1\niMac, : 1\niPad. : 1\niPhone, : 1\niPod, : 1\niTunes : 2\nif : 1\nillegal : 1\nimmigrants, : 1\nimportant : 1\nin : 41\nincluding : 1\nindulged : 1\nindustrial : 1\nindustry : 2\ninitially : 1\ninitiate : 1\ninstead.[18] : 1\ninterface : 1\ninto : 1\nintroduced : 1\ninventor, : 1\ninvolve : 1\nis : 1\nit : 2\nit&apos;s : 2\nits : 2\njail : 1\njoined : 1\njust : 1\nkilled : 1\nknew : 1\nknowing, : 1\nlarger : 1\nlaser : 1\nlater : 3\nlater, : 1\nlatter : 1\nlaw, : 1\nleading : 1\nleave : 1\nleaving : 1\nled : 1\nleft : 1\nlife : 1\nlife.[8] : 1\nline : 1\nlived : 1\nlong : 1\nlooking : 1\nlot : 1\nlove : 2\nloved : 1\nmachinist.[15] : 1\nmade : 3\nmagnate, : 1\nmajority : 1\nman&quot;, : 1\nmarijuana : 1\nmarkets. : 1\nmarried : 2\nmarry : 1\nmarry.[12] : 1\nmass-produced : 2\nmaternal : 1\nmatter : 1\nme : 2\nme, : 2\nme. : 1\nmember : 1\nmembers : 1\nmerged : 1\nmerger, : 1\nmet : 1\nmicrocomputer : 1\nmillionaire : 1\nmind, : 1\nmistake. : 1\nmodern : 1\nmonths : 2\nmore.&quot;[12] : 1\nmost : 1\nmother : 3\nmother&apos;s : 1\nmother, : 1\nmothers, : 1\nmouse-driven : 1\nmove : 1\nmoves, : 1\nmuch : 2\nmy : 1\nneither : 1\nneuroendocrine : 1\nnew : 2\nnot : 8\nnoted : 1\nnotes : 1\nnothing : 1\nof : 41\noff : 1\nofficer : 1\nofficial : 2\non : 6\nonce : 1\none : 1\nonly : 2\nonto : 1\noption : 1\nor : 1\noriginal : 1\nostensible : 1\nout : 3\nout,[5] : 1\npancreatic : 1\npapers.[12] : 1\nparents : 4\nparents&quot; : 1\nparents, : 1\nparents.&quot;[19] : 1\npart : 1\npersonal : 2\npersonality.&quot;[15] : 1\npioneers : 1\nplace.&quot;[17] : 1\nplaced : 2\nplatform : 1\nplatform, : 1\npolitical : 2\npossible : 1\npotential : 1\npower : 1\npregnancy, : 1\npregnant : 1\nprinter : 1\nprocess: : 1\nproduce : 1\nproducts : 1\npromised : 1\npromptly : 1\npublishing : 1\npursued : 1\nput : 2\nquietly : 1\nraised : 2\nraising : 1\nramifications: : 1\nreally : 2\nrebuilt : 1\nrecognized : 1\nreferred : 2\nrefused : 1\nregard : 1\nrelated : 1\nrelationship.[12] : 1\nreleasing : 1\nreplaced : 1\nreport : 1\nreporter : 1\nresemblance : 1\nrespiratory : 1\nreturn : 1\nrevived : 1\nrevolution : 1\nrise : 1\nsadly, : 1\nsame : 1\nsaw : 1\nsay : 1\nscared : 1\nschool, : 2\nscience.[11] : 1\nseeking : 1\nself-made : 1\nsell : 1\nseries : 1\nsettled : 1\nseveral : 1\nshame : 1\nshared : 1\nshareholder : 1\nshe : 6\nsheltered : 1\nship : 1\nsign : 1\nsingle : 1\nsister, : 1\nsix : 1\nso : 3\nsometimes : 1\nson : 2\nspecialized : 1\nspent : 2\nsperm : 2\nspinout : 1\nstart : 1\nstate-of-the-art : 1\nstated : 4\nstates : 1\nstigma : 1\nstrong : 1\nstruggle, : 1\nstudent : 1\nstudy : 2\nstudying : 1\nsubject : 1\nsuccessful : 1\nsudden : 1\nsuited : 1\nsummer : 1\nsupport. : 1\ntake : 2\ntaking : 1\ntaking, : 1\ntattoos, : 1\nteaching : 1\ntelling : 1\nten : 1\nthat : 22\nthat[18] : 1\nthe : 66\ntheir : 5\nthem : 3\nthen : 3\nthere : 2\nthey : 5\nthing, : 1\nthings&quot; : 1\nthis : 1\nthought : 1\nthree : 1\nthrough : 1\ntime : 2\ntime, : 1\ntime. : 1\nto : 42\ntold : 3\ntoo : 2\ntook : 2\ntough : 1\ntour : 1\ntraditional : 1\ntraveled : 2\ntumor : 1\ntumor. : 1\ntwo : 3\ntyrant, : 1\nundergraduate : 1\nunsuccessful : 1\nunusual.&quot;[14] : 1\nunwed : 1\nup : 6\nupped : 1\nupset : 1\nused : 1\nuser : 1\nvector : 1\nverge : 1\nvery : 1\nvisionaries : 1\nvisual : 1\nwant : 3\nwanted : 3\nwar. : 1\nwas : 33\nwas, : 1\nwasn&apos;t : 1\nway : 1\nwe : 2\nwealth : 1\nwealthy.&quot;[18] : 1\nwedlock : 1\nwell-educated, : 1\nwent : 1\nwere : 10\nwhen : 4\nwhere : 1\nwhich : 2\nwhile : 1\nwho : 5\nwhom : 1\nwidely : 1\nwife : 2\nwith : 15\nwithout : 1\nwomen : 1\nwon : 1\nwork.[12][15] : 1\nworked : 1\nwould : 6\nyear : 1\nyears : 2\nyoung : 1\nالجندلي) : 1\nالفتاح : 1\nعبد : 1\n– : 1\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["new_counts=counts.sortBy( lambda x : x[1] , False)  #we use the question 1 and we just modifiy the order of the data by sorting them using their second arguments x[1]\nfor (count,word) in new_counts.take(5):             #we print only the five first word of our data \n  print(\"%s : %i\" % (count,word))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">the : 66\nand : 53\na : 45\nto : 42\nin : 41\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["new_counts2=counts.filter( lambda x : len(x[0])>4 )       #we use again the data in \"counts\" but we filter and we keep only those who have more than five letter\nnew_counts2=new_counts2.sortBy( lambda x : x[1] , False)  #then we sort them as in Question 2 \nfor (count,word) in new_counts2.take(5):\n  print(\"%s : %i\" % (count,word))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Apple : 11\nClara : 8\nJandali : 8\nJobs&apos;s : 8\nSchieble : 8\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["edgelist = sc.textFile(\"/FileStore/tables/edgelist.txt\")\nidslabels = sc.textFile(\"/FileStore/tables/idslabels.txt\")\n\nlines_edgelist =edgelist.flatMap(lambda line: line.split(\" \")[1:])    #we don't keep the first element of the line, because it doesn't count in the in-degree       \npairs = lines_edgelist.map( lambda s :(s,1))\n  counts = pairs.reduceByKey(lambda a,b : a+b)                          #we count the in-degree of every pages\n\nlines_idslabels = idslabels.flatMap(lambda line : line.split(\"\\n\"))   \ncouples = lines_idslabels.map (lambda s : (s.split(\" \")[0],(\" \").join(s.split(\" \")[1:])))  #the first element of the couple is the id of the page, and the second is the name of the page\njointure = couples.join(counts)                                                            #we join with the id, so we have (the id, (the name of the website, his in-dregree))\njointure_sorted = jointure.sortBy(lambda a : a[1][-1], False).collect()                    #we sort the in-dregrees\nresultat = jointure_sorted[:10]\nfor i in resultat : \n  print(i)\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&apos;60589&apos;, (&apos;United States&apos;, 8145))\n(&apos;30594&apos;, (&apos;France&apos;, 7799))\n(&apos;24449&apos;, (&apos;Communes of France&apos;, 5740))\n(&apos;26539&apos;, (&apos;Departments of France&apos;, 5299))\n(&apos;51359&apos;, (&apos;Regions of France&apos;, 4064))\n(&apos;23683&apos;, (&apos;City&apos;, 3832))\n(&apos;52174&apos;, (&apos;Romania&apos;, 3527))\n(&apos;20409&apos;, (&apos;Category:Rivers in Romania&apos;, 2978))\n(&apos;59931&apos;, (&apos;Tributary&apos;, 2799))\n(&apos;28563&apos;, (&apos;England&apos;, 2277))\n</div>"]}}],"execution_count":6}],"metadata":{"name":"TP 2 Spark","notebookId":1215196057622588},"nbformat":4,"nbformat_minor":0}
